# Circular SMOTE: Implementation of the Proposed Method for Imbalanced Data

## Overview

This repository implements the oversampling method presented in our paper on **Circular SMOTE**. In many real-world datasets, the minority class is under-represented, leading to biased classifiers. Standard SMOTE creates synthetic samples by linearly interpolating between a minority sample and one of its neighbors. In contrast, **Circular SMOTE** defines a circular (or hyperspherical) region using two minority samples and uniformly samples within that region to generate synthetic data.

In our approach:
1. **Neighbor Selection:**  
   For each minority sample \( x \), we identify its \( k \)-nearest neighbors (excluding \( x \) itself) and randomly select one neighbor, \( x_{\text{neighbor}} \).

2. **Defining the Synthetic Region:**  
   We compute the midpoint:
   $$
   m = \frac{x + x_{\text{neighbor}}}{2}
   $$
   and define the radius as half the Euclidean distance between \( x \) and \( x_{\text{neighbor}} \):
   $$
   r = \frac{\| x - x_{\text{neighbor}} \|}{2}
   $$
   The circle (or hypersphere in higher dimensions) centered at \( m \) with radius \( r \) is then used as the region for generating new samples.

3. **Uniform Sampling:**  
   A synthetic sample is generated by:
   - Creating a random unit vector \( u \) in the feature space.
   - Drawing a random radius factor \( r_{\text{rand}} \) (with proper scaling to ensure uniform sampling):
     $$
     r_{\text{rand}} = r \times (\text{rand})^{\frac{1}{d}}
     $$
     where \( \text{rand} \) is a random number in \([0, 1]\) and \( d \) is the number of features.
   - The new sample is computed as:
     $$
     x_{\text{synthetic}} = m + r_{\text{rand}} \times u
     $$

4. **Full Pipeline:**  
   We apply Circular SMOTE on the minority class of the Breast Cancer dataset (from scikit-learn or via the _mlbench_ package in R). After oversampling, we combine the synthetic samples with the original training data and train a K‑Nearest Neighbors (KNN) classifier. We then compare the performance of the classifier trained on the resampled data with one trained on the original imbalanced data.

## Repository Structure

- **README.md**: This file.
- **docs/**: Contains documentation and the translated/summarized version of the paper.
- **python/circular_smote_pipeline.py**: Python implementation.
- **R/circular_smote_pipeline.R**: R implementation.

## Python Implementation

The Python pipeline performs the following steps:
- Load the Breast Cancer dataset (from `sklearn.datasets.load_breast_cancer`).
- Split the data into training and testing sets.
- Identify the minority class in the training data (assumed to be malignant).
- Compute the oversampling percentage needed to balance the classes.
- Apply the Circular SMOTE algorithm on the minority samples.
- Combine the synthetic samples with the original training data.
- (Optionally) perform feature selection using ANOVA F-values.
- Train a KNN classifier and evaluate its performance on the test set.
- For comparison, the classifier is also trained without oversampling.

The complete Python code is provided in [python/circular_smote_pipeline.py](python/circular_smote_pipeline.py).

## R Implementation

The R pipeline replicates the same methodology:
- Load the Breast Cancer dataset (using the `BreastCancer` dataset from the **mlbench** package).
- Preprocess the data (remove missing values, convert features to numeric).
- Split the data into training and testing sets.
- Identify the minority class (assumed to be malignant).
- Compute the oversampling percentage and apply Circular SMOTE (using a custom function with **FNN** for nearest neighbors).
- Combine the oversampled data with the original training set.
- Train a k‑NN classifier (using the **class** package) and evaluate performance.
- Compare results with a classifier trained on the original imbalanced training set.
- Visualize the class distribution before and after oversampling.

The complete R code is provided in [R/circular_smote_pipeline.R](R/circular_smote_pipeline.R).
